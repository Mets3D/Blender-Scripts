I will try to describe how I would expect a node-based rigging system to work.
Disclaimer: These are my initial thoughts, with no experience with any other node-based rigging system, and with a limited understanding of how transformations are calculated. I intend to learn more about these things and iterate on these thoughts in the future.

Goals:
- Allow rig authors to cut down on the amount of helper bones, that is, bones that are responsible solely to store some transformations, which are not meant to be controlled by animators, and aren't bones that directly deform the mesh.
- Make creating and understanding rigs more intuitive.
- Combine functionality of Drivers and Constraints.
- Provide the low level power that usually comes with node systems.
- Possibly improve rig performance.
- Improve dependency graph granularity

Todo: Elaborate on how each of these goals would be achieved.

## Who owns the nodegraph? ##
The bone. Each bone has one nodegraph.
This nodegraph has a singule output node, similar to material nodegraphs. This is the only node that actually affects the scene. Every other node is simply for gathering and processing information.

The output node would have pins for as many bone properties as possible.
The most important of these properties is the bone's transforms.
There could also be pins for BBone settings, Envelope settings, custom properties, viewport display settings, etc.
Of course we don't want the output node to be a monstrosity, so most of these things could be hidden by default behind some UX wizardry.

## What can the nodegraph control? ##
Only the properties listed in the output node, on this one bone.

If a property is controlled by this nodegraph, how is it determined whether users still have control over them or not? Most importantly, transforms.
For Booleans, the user could certainly not be able to keep control. They can only regain it by unplugging the relevant value from the nodegraph's output node. For that, there could be a shortcut in the right click menu or whatever UX solution.

For transforms
Solution 1: Give the nodegraph access to the bone's pose transforms(transformations performed by the user), and then the author of the node graph can choose to use those transforms in some way or not. This would determine if attempting to move the bone would do anything or not. It would also allow for weird behaviour, like making it so that attempting to move the bone to the left, will move it to the right.
Solution 2: A setting, like a checkbox, determining whether the bone can be controlled further after the final outputted transforms of the node graph or not.

For single values, we have similar options as for transforms, but the weird behavior when changing values (Soluion 1) can be even weirder, since we could end up sliding a slider to the left and then have its value increase.
But on the other hand, Solution 2 would mean adding a checkbox/setting for every single property... and we would have a problem where resetting a property to its "default value"(usually 0 or 1) would not actually do so. For example, if the nodegraph is outputting the value 2.5 to a property, and the user increased it to 5, they might want to set it to 0 by entering 0, but it would instead go back to 2.5.
That's fine, if the user enters a number, we would calculate the "real" user-inputted value relative to the nodegraph output. So, if the nodegraph output is 2.5, and the user enters 0, we would calculate the "true" user input to be 0-2.5, or -2.5. And so the final value would be 0. If the user wanted to truly clear their input, they would have to it differently than manually entering the default value and pressing enter. There would probably be a right click->reset to default.


Properties controlled by the nodegraph could be indicated by a color, like how drivers are indicated by purple.